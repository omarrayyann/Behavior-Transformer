{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavorial Transfomer Implementation Walkthrough\n",
    "Adapted from the original BeT code (https://github.com/notmahi/bet) and paper (https://arxiv.org/pdf/2206.11251)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries Required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from gpt import GPT, GPTConfig\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-Means Based (De/En)coder: $ a:= A_{\\lfloor a \\rfloor}$ + $ \\langle a \\rangle$\n",
    "The first component of a Behavorial Transformer (BeT) is a K-means based encoder and decoder learned prior to the task training and testing.\n",
    "\n",
    "<img width=\"600px\" src=\"images/K-Mean.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Encoder:** Given an action $a$, the ecnoder component would discretize it into an action bin **$\\lfloor a \\rfloor$** and a residual action **$ \\langle a \\rangle $**, such that $ a := A_{\\lfloor a \\rfloor} + \\langle a \\rangle $.\n",
    "\n",
    "**Decoder:** Given an action bin **$\\lfloor a \\rfloor$** and the residual action **$ \\langle a \\rangle $**, it would output **a** given by $ a := A_{\\lfloor a \\rfloor} + \\langle a \\rangle $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder:\n",
    "\n",
    "    def __init__(self, action_dim, num_bins, actions):\n",
    "        self.action_dim = action_dim\n",
    "        self.num_bins = num_bins\n",
    "        # Note: Using sklearn KMeans iteration for simplicity\n",
    "        self.kmeans = KMeans(n_clusters=self.num_bins) \n",
    "        self.kmeans.fit(actions)\n",
    "\n",
    "    def encode(self, action):\n",
    "\n",
    "        batch_size, sequence_length, action_dim = action.shape\n",
    "\n",
    "        # Reshaping to exclude batch size        \n",
    "        action = action.reshape((batch_size*sequence_length,action_dim))\n",
    "        \n",
    "        action_bin = self.kmeans.predict(action)\n",
    "        action_center = self.get_center(action_bin)\n",
    "        action_residual = action - action_center\n",
    "\n",
    "        # Reshaping to include batch size\n",
    "        action_residual = action_residual.reshape((batch_size, sequence_length, action_dim))\n",
    "        action_bin = action_bin.reshape((batch_size, sequence_length, 1))\n",
    "\n",
    "        # Returning the Action Bin and the Action Residual\n",
    "        return torch.tensor(action_bin,dtype=torch.int64), action_residual.to(torch.float)\n",
    "        \n",
    "    def decode(self, action_bin, action_residual):\n",
    "        action_center = self.get_center(action_bin)\n",
    "        action = action_residual + action_center\n",
    "        # Returning the associated action\n",
    "        return action\n",
    "    \n",
    "    def get_center(self, action_bin):\n",
    "        return torch.tensor(self.kmeans.cluster_centers_[action_bin].squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tesing the Encoder/Decoder Component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Action Bin Shape:\t torch.Size([2, 10, 1])\n",
      "Encoded Action Residual Shape:\t torch.Size([2, 10, 3])\n",
      "Original:\t [[[0.24479037523269653, 0.6477630734443665, 0.2133672833442688], [0.18716996908187866, 0.28942757844924927, 0.03588855266571045], [0.15689361095428467, 0.668989896774292, 0.7439367175102234], [0.4677286744117737, 0.9012507200241089, 0.17209213972091675], [0.7616887092590332, 0.636254608631134, 0.5112188458442688], [0.27330106496810913, 0.29068005084991455, 0.1763436198234558], [0.001971602439880371, 0.0765460729598999, 0.9579184055328369], [0.3830993175506592, 0.2187047004699707, 0.33932608366012573], [0.5947545766830444, 0.18389487266540527, 0.8536553978919983], [0.30301356315612793, 0.06573772430419922, 0.2929864525794983]], [[0.20370203256607056, 0.05925190448760986, 0.619742214679718], [0.9325045347213745, 0.657662034034729, 0.5698668956756592], [0.7619799971580505, 0.9337874054908752, 0.590020477771759], [0.9497239589691162, 0.6005738973617554, 0.8144691586494446], [0.7440366744995117, 0.2086532711982727, 0.7599707841873169], [0.7105684280395508, 0.2818748354911804, 0.7813649773597717], [0.7350009679794312, 0.04174011945724487, 0.8712361454963684], [0.6030629277229309, 0.5917947888374329, 0.21774822473526], [0.6240254044532776, 0.5903610587120056, 0.5091619491577148], [0.1473010778427124, 0.00902026891708374, 0.17859405279159546]]]\n",
      "Decoded Action:\t [[[0.24479036185206204, 0.647763075877209, 0.2133672834963215], [0.18716995570124417, 0.2894275808820919, 0.035888545367182556], [0.1568936226414699, 0.6689899005726272, 0.7439367168893416], [0.4677286759323004, 0.9012507224569515, 0.17209213987296945], [0.7616887209462184, 0.6362546124294692, 0.5112188359101613], [0.27330106648863584, 0.2906800532827572, 0.17634361997550851], [0.0019716141270655907, 0.07654606185707391, 0.9579184104998906], [0.3830993190711859, 0.21870470290281335, 0.33932608381217844], [0.5947545734690685, 0.18389486156257928, 0.8536553954084714], [0.30301356467665463, 0.06573772673704187, 0.292986452731551]], [[0.20370204425325578, 0.05925189338478387, 0.6197422196467717], [0.9325045464085597, 0.6576620378330642, 0.5698669006427128], [0.7619800088452358, 0.9337873943880493, 0.5900204827388127], [0.9497239706563014, 0.60057389370951, 0.8144691598912079], [0.7440366712855357, 0.2086532600954467, 0.7599707844977577], [0.7105684248255748, 0.2818748392895156, 0.7813649776702125], [0.7350009647654552, 0.04174010835441888, 0.8712361430128415], [0.6030629292434576, 0.5917947912702755, 0.2177482248873127], [0.6240254012393016, 0.5903610550597602, 0.5091619392236073], [0.1473010644620779, 0.00902027134992639, 0.17859405294364816]]]\n"
     ]
    }
   ],
   "source": [
    "num_bins = 2\n",
    "batch_size = 2\n",
    "total_action_batch_size = 5\n",
    "sequence_length = 10\n",
    "action_dim = 3\n",
    "total_actions = 100\n",
    "\n",
    "actions = torch.rand((total_actions,action_dim))\n",
    "\n",
    "encoder_decoder = EncoderDecoder(action_dim,num_bins,actions)\n",
    "\n",
    "test_input = torch.rand((batch_size,sequence_length,action_dim))\n",
    "action_bin, action_residual = encoder_decoder.encode(test_input) # Expected Output is a [1.0, 2.0] residual\n",
    "print(\"Encoded Action Bin Shape:\\t\", action_bin.shape)\n",
    "print(\"Encoded Action Residual Shape:\\t\", action_residual.shape)\n",
    "decoded = encoder_decoder.decode(action_bin=action_bin,action_residual=action_residual)\n",
    "print(\"Original:\\t\", test_input.numpy().tolist())\n",
    "print(\"Decoded Action:\\t\", decoded.numpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. nanoGPT for initial Action Bins $\\lfloor a \\rfloor$\n",
    "The second component of BeT is a transformer that takes the history of the last $L$ observations $[o_{i-L}, ... o_{i-1}, o_i]$ as an input, and outputs a predicted probability sequence of the fixed possible action bins of the next predicted action to get $\\lfloor a_{i+1} \\rfloor$.\n",
    "\n",
    "<img width=\"700px\" src=\"images/gpt.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gpt(observation_dim, num_bins, sequence_length):\n",
    "    gpt = GPT(GPTConfig(\n",
    "        block_size=sequence_length,\n",
    "        input_dim=observation_dim,\n",
    "        output_dim=num_bins,\n",
    "        n_layer=6,\n",
    "        n_head=8,\n",
    "        n_embd=256,\n",
    "    ))\n",
    "    return gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tesing the GPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 4.74M\n",
      "Observation Shape:\t\t torch.Size([1, 5, 1])\n",
      "Action Bins Logits Shape:\t torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "observation_dim = 1\n",
    "num_bins = 10\n",
    "sequence_length = 5\n",
    "gpt = make_gpt(observation_dim,num_bins,sequence_length)\n",
    "batch_size = 1\n",
    "\n",
    "observations_history = torch.rand((batch_size,sequence_length,observation_dim))\n",
    "logits = gpt(observations_history)\n",
    "\n",
    "print(\"Observation Shape:\\t\\t\", observations_history.shape)\n",
    "print(\"Action Bins Logits Shape:\\t\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transformer Head for final Action Residuals $ \\langle a \\rangle $ and Bins $\\lfloor a \\rfloor$\n",
    "The last component of BeT takes the action bins $\\lfloor a \\rfloor$ logits outputed by the transformer and embeds them into a representation that includes the final action bin $\\lfloor a \\rfloor$ and action residual $ \\langle a \\rangle $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, num_bins, action_dim, drop_out=0.2):\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        self.num_bins = num_bins\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        linear_in_dim = num_bins\n",
    "        linear_out_dim = num_bins*(action_dim+1)\n",
    "        \n",
    "        self.layer = nn.Linear(linear_in_dim,linear_out_dim)\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "       \n",
    "    def forward(self, transformer_logits):\n",
    "        \n",
    "        # Transformer Logits: (Batch_Size , Sequence_Length , Number_Action_Bins)\n",
    "\n",
    "        x = self.layer(transformer_logits)\n",
    "        action_data = self.dropout(x)\n",
    "        # Action Data: (Batch_Size , Sequence_Length , Number_Action_Bins*(Action_dim+1))\n",
    "\n",
    "        seq_action_bins_logits, all_seq_action_residuals = torch.split(action_data, [num_bins, num_bins * action_dim], dim=-1)\n",
    "        # Sequence Action Bins Logits:   (Batch_Size , Sequence_Length, Number_Action_Bins)\n",
    "        # All Sequence Action Residuals: (Batch_Size , Sequence_Length, Number_Action_Bins*Action_dim)\n",
    "        \n",
    "        # Softmaxing the sequence action bins logits to get the probability per bin at every sequence index\n",
    "        seq_action_bins_probs = torch.softmax(seq_action_bins_logits,dim=-1)\n",
    "        seq_action_bins = torch.multinomial(seq_action_bins_probs.view(-1, num_bins), num_samples=1)\n",
    "        seq_action_bins = seq_action_bins.reshape((batch_size,sequence_length,1))\n",
    "        # Sequence Action Bins: (Batch_Size , Sequence_Length, 1)\n",
    "\n",
    "        # Keeping the action resiudals for the selected action bin\n",
    "        flat_all_seq_action_residuals = all_seq_action_residuals.reshape((batch_size*sequence_length, num_bins, action_dim))\n",
    "        flat_seq_action_residuals = flat_all_seq_action_residuals[torch.arange(flat_all_seq_action_residuals.shape[0]),seq_action_bins.flatten()]\n",
    "        seq_action_residuals = flat_seq_action_residuals.reshape((batch_size, sequence_length, action_dim))\n",
    "        # Sequence Action Residuals: (Batch_Size , Sequence_Length, Action_dim)\n",
    "\n",
    "        return {\"seq_action_bins\": seq_action_bins, \"seq_action_residuals\": seq_action_residuals, \"seq_action_bins_logits\": seq_action_bins_logits,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tesing the Transformer Head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Residuals Shape:\t\t torch.Size([5, 10, 3])\n",
      "Actions Bins Shape:\t\t torch.Size([5, 10, 1])\n",
      "Actions Bins Logits Shape:\t torch.Size([5, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_bins = 2\n",
    "sequence_length = 10\n",
    "action_dim = 3\n",
    "logits = torch.rand((batch_size,sequence_length,num_bins))\n",
    "\n",
    "head = Head(num_bins,action_dim)\n",
    "output = head(logits)\n",
    "seq_action_bins, seq_action_residuals, seq_action_bins_logits = output[\"seq_action_bins\"], output[\"seq_action_residuals\"], output[\"seq_action_bins_logits\"]\n",
    "\n",
    "print(\"Action Residuals Shape:\\t\\t\", seq_action_residuals.shape)\n",
    "print(\"Actions Bins Shape:\\t\\t\", seq_action_bins.shape)\n",
    "print(\"Actions Bins Logits Shape:\\t\", seq_action_bins_logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Focal Loss for Action Bins $\\lfloor a \\rfloor$\n",
    "\n",
    "$L_{focal}(p_t) = -(1 - p_t)^\\gamma \\log(p_t)$\n",
    "\n",
    "Focal loss is used to handle the class imbalance in action bins by assigning more weight for hard-to-classify examples inorder to be improve performance in predicting low-probability classes (important for multi-modal behavior distributions​​)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/notmahi/miniBET/blob/main/behavior_transformer/bet.py\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma: float = 0, size_average: bool = True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logpt = F.log_softmax(input, dim=-1)\n",
    "        logpt = logpt.gather(1, target.view(-1, 1)).view(-1)\n",
    "        pt = logpt.exp()\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. BeT: Stitching all the Componenets Together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeT(nn.Module):\n",
    "\n",
    "    def __init__(self, observation_dim, action_dim, num_bins, sequence_length, actions, gamma=2.0):\n",
    "        super(BeT, self).__init__()\n",
    "\n",
    "        self.observation_dim = observation_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.num_bins = num_bins\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Initializing the Encoder Decoder which is based on the K-Means\n",
    "        self.encoderDecoder = EncoderDecoder(action_dim, num_bins, actions)\n",
    "\n",
    "        # Initializing the GPT model to be used for sequence to sequence modeling\n",
    "        self.gpt = make_gpt(observation_dim,num_bins,sequence_length)\n",
    "        \n",
    "        # Initializing the Head that takes the sequence output of the GPT to return the action bin and action residual\n",
    "        self.head = Head(num_bins, action_dim)\n",
    "\n",
    "        # Residual Loss Function \n",
    "        self.residual_criterion = nn.MSELoss()\n",
    "\n",
    "        # Action Bins Loss Function \n",
    "        self.bin_criterion = FocalLoss(gamma)\n",
    "\n",
    "    def forward(self, observations_history, train_data=False):\n",
    "        \n",
    "        # (Batch Size, Sequence Lenght, Number of Action Bins)\n",
    "        gpt_logits = self.gpt(observations_history)\n",
    "\n",
    "        head_output = self.head(gpt_logits)\n",
    "        # Predicted Sequence Action Bins: (Batch_Size, Sequence_Length, 1)\n",
    "        predicted_seq_action_bins = head_output[\"seq_action_bins\"]\n",
    "        # Predicted Sequence Action Residuals: (Batch_Size, Sequence_Length, Action_dim)\n",
    "        predicted_seq_action_residuals = head_output[\"seq_action_residuals\"]\n",
    "        # Predicted Sequence Action Bins Logits: (Batch_Size, Sequence_Length, Number_Action_Bins)\n",
    "        seq_action_bins_logits = head_output[\"seq_action_bins_logits\"]\n",
    "\n",
    "        # Predicted Action: (Batch_Size, Action_dim)\n",
    "        predicted_action = self.encoderDecoder.decode(predicted_seq_action_bins[:,-1,0],predicted_seq_action_residuals[:,-1,:])\n",
    "\n",
    "        # No Training: Inference Only (No Loss Calculation)\n",
    "        if not train_data:\n",
    "            return predicted_action\n",
    "        # Training: Return Predicted Action and Training Required Data\n",
    "        else:\n",
    "            return {\"seq_action_bins_logits\":seq_action_bins_logits, \"predicted_seq_action_residuals\":predicted_seq_action_residuals}\n",
    "\n",
    "    def learn(self, observations_history, actions_history, optimizer, residual_loss_scale=1e3):\n",
    "        \n",
    "        # Target Sequence Action Bins: (Batch_Size, Sequence_Length, Number_Action_Bins)\n",
    "        # Target Sequence Action Residuals: (Batch_Size, Sequence_Length, Action_Dims)\n",
    "        target_seq_action_bin, target_seq_action_residuals = encoder_decoder.encode(actions_history)\n",
    "\n",
    "        training_data = self.forward(observations_history, train_data=True)\n",
    "        # Predicted Sequence Action Residuals: (Batch_Size, Sequence_Length, Action_dim)\n",
    "        predicted_seq_action_residuals = training_data[\"predicted_seq_action_residuals\"]\n",
    "        # Predicted Sequence Action Bins Logits: (Batch_Size, Sequence_Length, Number_Action_Bins)\n",
    "        seq_action_bins_logits = training_data[\"seq_action_bins_logits\"]\n",
    "\n",
    "        # Residual Loss\n",
    "        action_residual_loss = self.residual_criterion(predicted_seq_action_residuals, target_seq_action_residuals)\n",
    "\n",
    "        # Actions Bin Loss\n",
    "        seq_action_bins_logits = seq_action_bins_logits.reshape((-1,seq_action_bins_logits.shape[-1]))\n",
    "        target_seq_action_bin = target_seq_action_bin.reshape((-1,1))\n",
    "        action_bins_loss = self.bin_criterion(seq_action_bins_logits, target_seq_action_bin)\n",
    "\n",
    "        # Total Loss = Actions Bin Loss + Residual Loss * Loss Scale\n",
    "        total_loss = action_bins_loss + action_residual_loss*residual_loss_scale\n",
    "        \n",
    "        # Training Step\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        return {\"total_loss\": total_loss, \"action_bins_loss\": action_bins_loss, \"action_residual_loss\": action_residual_loss}\n",
    "    \n",
    "    # Source: https://github.com/notmahi/miniBET/blob/main/behavior_transformer/bet.py\n",
    "    def create_optimizer(self, weight_decay, learning_rate, betas):\n",
    "        optimizer = self.gpt.configure_optimizers(\n",
    "            weight_decay=weight_decay,\n",
    "            learning_rate=learning_rate,\n",
    "            betas=betas,\n",
    "        )\n",
    "        optimizer.add_param_group({\"params\": self.head.parameters()})\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the BeT Combined Componenet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 4.74M\n",
      "Action Shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "num_bins = 2\n",
    "batch_size = 2\n",
    "total_action_batch_size = 5\n",
    "sequence_length = 10\n",
    "action_dim = 3\n",
    "total_actions = 100\n",
    "\n",
    "actions_collection = torch.rand((total_actions,action_dim))\n",
    "bet = BeT(observation_dim, action_dim, num_bins, sequence_length, actions_collection)\n",
    "\n",
    "observations_history = torch.rand((batch_size,sequence_length,observation_dim))\n",
    "predicted_action = bet(observations_history)\n",
    "print(\"Action Shape: \", predicted_action.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_loss': tensor(295.8558, grad_fn=<AddBackward0>),\n",
       " 'action_bins_loss': tensor(0.2179, grad_fn=<MeanBackward0>),\n",
       " 'action_residual_loss': tensor(0.2956, grad_fn=<MseLossBackward0>)}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet_optimizer = bet.create_optimizer(weight_decay=0.0002,learning_rate=0.00001,betas=[0.9,0.999])\n",
    "\n",
    "observations_history = torch.rand((batch_size,sequence_length,observation_dim))\n",
    "actions_history = torch.rand((batch_size,sequence_length,action_dim))\n",
    "bet.learn(observations_history, actions_history, bet_optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
